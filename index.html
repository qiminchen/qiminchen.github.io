<!DOCTYPE HTML>
<!-- Adopted from https://github.com/jonbarron/website, very appreciate the code-->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script type="text/javascript" src="main/js/hidebib.js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Qimin Chen</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">

  <meta name="author" content="Qimin Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="main/stylesheet.css">
  <link rel="stylesheet" type="text/css" href="main/css/style.css">
  <link rel="icon" type="image/png" href="main/images/sfu_logo.png">
<!--   <link rel="icon" type="image/png" href="main/images/icon.png"> -->
</head>

<body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;
    border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:50px">
        <tbody>
        <tr style="padding: 0px">
            <td style="padding:0px">

                <!-- Introduction -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
                margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr style="padding:0px">
                        <td style="padding:2.5%;width:70%;vertical-align:middle">
                            <p style="text-align:center;margin-bottom:20px">
                                <strong><name>Qimin Chen</name></strong>
                            </p>
                            <p>
                                I am a Ph.D. student in <a href="https://gruvi.cs.sfu.ca/">GrUVi lab</a> of
                                <a href="https://www.sfu.ca/computing.html"> School of Computing Science </a> at
                                <a href="https://www.sfu.ca/">Simon Fraser University</a>, under the supervision of
                                <a href="https://www.cs.sfu.ca/~haoz/">Prof. Hao (Richard) Zhang</a>.
                            </p>
                            <p>
                                Before that, I received my M.S. degree in Computational Science from
                                <a href="https://ucsd.edu/" target="_blank">UC San Diego</a>, where I worked at
                                <a href="http://jacobsschool.ucsd.edu/visualcomputing/">Center for Visual Computing Lab</a>
                                advised by <a href="https://cseweb.ucsd.edu/~kriegman/">Prof. David J. Kriegman</a>. I also worked at
                                Machine Learning, Perception, and Cognition
                                Lab (mlPC) advised by <a href="http://pages.ucsd.edu/~ztu/">Prof. Zhuowen Tu</a>.
                                Before that, I received my B.S degree in Computer Science and Technology from Fuzhou University.
                            </p>
                            <p style="text-align:center">
                                qca43 at sfu dot ca &nbsp/&nbsp
                                <a href="main/data/QiminChenCV.pdf">CV</a> &nbsp/&nbsp
                                <a href="https://www.linkedin.com/in/q7minchen/">LinkedIn</a> &nbsp/&nbsp
                                <a href="https://scholar.google.com/citations?user=N5MghGIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                                <a href="https://github.com/qiminchen">Github</a>
                            </p>
                            <br>
                            <a href="main/images/mind-map.gif">
                                <img style="width: 3%;max-width: 3%;border-radius: 3%;vertical-align: middle" alt="mind map"
                                     src="main/images/mind-map.gif" class="hoverZoomLink">
                            </a>
                            &nbsp;&nbsp;
                            <span style="color: orange">
                                <strong>
                                    <a href="https://aideadlin.es/?sub=CV" style="color: orange;font-size: 14px" target="_blank">
                                        AI Conference Deadlines</a>
                                </strong>
                            </span>
                            <br>
                            <a href="main/images/cvf.png">
                                <img style="width: 3%;max-width: 3%;border-radius: 3%;vertical-align: middle" alt="cvf"
                                     src="main/images/cvf.png" class="hoverZoomLink">
                            </a>
                            &nbsp;&nbsp;
                            <span style="color: orange">
                                <strong>
                                    <a href="https://openaccess.thecvf.com/menu" style="color: orange;font-size: 14px" target="_blank">
                                        CVF Open Access</a>
                                </strong>
                            </span>
                            <br>
                            <a href="main/images/3d.gif">
                                <img style="width: 3%;max-width: 3%;border-radius: 3%;vertical-align: middle" alt="3d"
                                     src="main/images/3d.gif" class="hoverZoomLink">
                            </a>
                            &nbsp;&nbsp;
                            <span style="color: orange">
                                <strong>
                                    <a href="https://github.com/yinyunie/3D-Shape-Analysis-Paper-List" style="color: orange;font-size: 14px" target="_blank">
                                        3D Shape Analysis Paper List</a>
                                    <br>
                                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                                    <a href="https://github.com/weihaox/awesome-neural-rendering" style="color: orange;font-size: 14px" target="_blank">
                                        Neural Rendering Paper List</a>
                                </strong>
                            </span>
                        </td>
                        <td style="padding:2.5%;width:40%;max-width:40%">
                            <a href="main/images/QiminChen.jpg">
                                <img style="width:100%;max-width:100%;border-radius:50%"
                                     alt="profile photo" src="main/images/QiminChen.jpg" class="hoverZoomLink">
                            </a>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <!-- Research interest -->
                <table style="width:100%;border:0px;border-spacing:0px;
                border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding-bottom:10px;padding-top:10px;padding-left:20px;padding-right:10px;width:100%;vertical-align:middle">
                            <heading>Research</heading>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
                margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding-bottom:20px;padding-top:10px;padding-left:20px;padding-right:10px;width:100%;vertical-align:middle">
                            <p>
                                My research interest mainly focuses on Computer Graphics, especially geometric modeling, 
                                3D shape generation and manipulation.
                            </p>
                        </td>
                    </tr>
                    </tbody>
                </table>
              
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
                margin-right:auto;margin-left:auto;">
                    <body>

                    <!--arxiv2024daenet-->
                    <tr>
                        <td style="padding-top:20px;padding-bottom:20px;padding-left:20px;padding-right:0px;width:35%;vertical-align:middle">
                            <img src='main/images/daenet.png' width="250" height="150"></div>
                        </td>
                        <td style="padding-bottom:15px;padding-top:15px;padding-right:5px;width:75%;vertical-align:middle">
                            <p>
                                <a href="https://github.com/czq142857/DAE-Net">
                                    <papertitle>DAE-Net: Deforming Auto-Encoder for fine-grained shape co-segmentation</papertitle>
                                </a>
                                <br>
                                <a href="https://czq142857.github.io/">Zhiqin Chen</a>,
                                <strong>Qimin Chen</strong>,
                                <a href="http://home.ustc.edu.cn/~zh2991/">Hang Zhou</a>,
                                <a href="https://www.cs.sfu.ca/~haoz/">Hao Zhang</a>
                                <br>
                                <em>SIGGRAPH, 2024 (Conference)</em>
                                <br>
                                <a href="https://arxiv.org/abs/2311.13125">pdf</a> /
                                <a href="https://github.com/czq142857/DAE-Net">code</a>
                            </p>
                            <p></p>
                            <p>
                                DAE-Net is an unsupervised 3D shape co-segmentation method that learns a set of deformable part templates from a shape collection, which 
                                yields high-quality, consistent, and fine-grained 3D shape co-segmentation.
                            </p>
                        </td>
                    </tr>

                    <!--arxiv2023shaddr-->
                    <tr>
                        <td style="padding-top:20px;padding-bottom:20px;padding-left:20px;padding-right:0px;width:35%;vertical-align:middle">
                            <img src='main/images/sigasia2023shaddr.gif' width="250" height="150"></div>
                        </td>
                        <td style="padding-bottom:15px;padding-top:15px;padding-right:5px;width:75%;vertical-align:middle">
                            <p>
                                <a href="https://qiminchen.github.io/shaddr/">
                                    <papertitle>ShaDDR: Interactive Example-Based Geometry and Texture Generation via 3D Shape Detailization and Differentiable Rendering</papertitle>
                                </a>
                                <br>
                                <strong>Qimin Chen</strong>,
                                <a href="https://czq142857.github.io/">Zhiqin Chen</a>,
                                <a href="http://home.ustc.edu.cn/~zh2991/">Hang Zhou</a>,
                                <a href="https://www.cs.sfu.ca/~haoz/">Hao Zhang</a>
                                <br>
                                <em>SIGGRAPH Asia, 2023 (Conference)</em>
                                <br>
                                <a href="https://arxiv.org/abs/2306.04889">pdf</a> /
                                <a href="">supplementary</a> /
                                <a href="https://github.com/qiminchen/ShaDDR">code</a> /
                                <a href="">project page</a>
                            </p>
                            <p></p>
                            <p>
                                The first example-based deep generative neural network for generating a high-resolution textured 3D shape through geometry detailization 
                                and conditional texture generation applied to an input coarse voxel shape.
                            </p>
                        </td>
                    </tr>

                    <!--arxiv2023d2csg-->
                    <tr>
                        <td style="padding-top:20px;padding-bottom:20px;padding-left:20px;padding-right:0px;width:35%;vertical-align:middle">
                            <img src='main/images/d2csg.png' width="250" height="150"></div>
                        </td>
                        <td style="padding-bottom:15px;padding-top:15px;padding-right:5px;width:75%;vertical-align:middle">
                            <p>
                                <a href="https://arxiv.org/abs/2301.11497">
                                    <papertitle>D<sup>2</sup>CSG: Unsupervised Learning of Compact CSG Trees with Dual Complements and Dropouts</papertitle>
                                </a>
                                <br>
                                <a href="https://fenggenyu.github.io/">Fenggen Yu</a>,
                                <strong>Qimin Chen</strong>,
                                <a href="http://mtanveer.com/">Maham Tanveer</a>,
                                <a href="https://www.sfu.ca/~amahdavi/">Ali Mahdavi-Amiri</a>,
                                <a href="https://www.cs.sfu.ca/~haoz/">Hao Zhang</a>
                                <br>
                                <em>NeurIPS, 2023</em>
                                <br>
                                <a href="https://arxiv.org/abs/2301.11497">arXiv</a>
                            </p>
                            <p></p>
                            <p>
                                D2CSG is a neural model composed of two dual and complementary network branches, with dropouts, for unsupervised 
                                learning of compact constructive solid geometry (CSG) representations of 3D CAD shapes.
                            </p>
                        </td>
                    </tr>

                    <!--arxiv2021unist-->
                    <tr>
                        <td style="padding-top:20px;padding-bottom:20px;padding-left:20px;padding-right:0px;width:35%;vertical-align:middle">
                            <img src='main/images/arxiv2021unist.gif' width="250" height="150"></div>
                        </td>
                        <td style="padding-bottom:15px;padding-top:15px;padding-right:5px;width:75%;vertical-align:middle">
                            <p>
                                <a href="https://qiminchen.github.io/unist/">
                                    <papertitle>UNIST: Unpaired Neural Implicit Shape Translation Network</papertitle>
                                </a>
                                <br>
                                <strong>Qimin Chen</strong>,
                                <a href="">Johannes Merz</a>,
                                <a href="">Aditya Sanghi</a>,
                                <a href="">Hooman Shayani</a>,
                                <a href="">Ali Mahdavi-Amiri</a>,
                                <a href="">Hao Zhang</a>
                                <br>
                                <em>CVPR, 2022</em>
                                <br>
                                <a href="https://arxiv.org/abs/2112.05381">pdf</a> /
                                <a href="unist/data/UNIST_supplementary.pdf">supplementary</a> /
                                <a href="https://github.com/qiminchen/UNIST">code</a> /
                                <a href="https://qiminchen.github.io/unist/">project page</a>
                            </p>
                            <p></p>
                            <p>
                                The first deep neural implicit model for general-purpose, unpaired shape-to-shape translation, in both 2D and 3D domains.
                                UNIST can learn both style-preserving content alteration and content-preserving style transfer.
                            </p>
                        </td>
                    </tr>
        
                    <!--chen2021coralnet-->
                    <tr>
                        <td style="padding-top:20px;padding-bottom:20px;padding-left:20px;padding-right:0px;width:35%;vertical-align:middle">
                            <img src='main/images/chen2021coralnet.png' width="250" height="150"></div>
                        </td>
                        <td style="padding-bottom:15px;padding-top:15px;padding-right:5px;width:75%;vertical-align:middle">
                            <p>
                                <a href="">
                                    <papertitle>A New Deep Learning Engine for CoralNet</papertitle>
                                </a>
                                <br>
                                <strong>Qimin Chen</strong>,
                                <a href="">Oscar Beijbom</a>,
                                <a href="">Stephen Chan</a>,
                                <a href="">Jessica Bouwmeester</a>,
                                <a href="">David Kriegman</a>
                                <br>
                                <em>ICCV Workshop on Computer Vision in the Ocean <a href="https://www.geomar.de/en/omv/ocean-vision-2021">
                                    (ICCVW)</a>,</em> 2021
                                <br>
                                <a href="https://openaccess.thecvf.com/content/ICCV2021W/OceanVision/papers/Chen_A_New_Deep_Learning_Engine_for_CoralNet_ICCVW_2021_paper.pdf">pdf</a> /
                                <a href="main/data/chen2021coralnet.bib">bibtex</a> /
                                <a href="https://coralnet.ucsd.edu/" target="_blank">coralnet</a> /
                                <a href="https://github.com/qiminchen/CoralNet">code</a> 
                            </p>
                            <p></p>
                            <p>
                                CoralNet is a cloud-based website and platform for manual, semi-automatic and automatic analysis of coral
                                reef images. Users access CoralNet through optimized web-based workflows for common tasks, other systems
                                can interface through API.
                            </p>
                        </td>
                    </tr>


                    <!--chen2020topology-->
                    <tr>
                        <td style="padding-top:20px;padding-bottom:20px;padding-left:20px;padding-right:0px;width:35%;vertical-align:middle">
                            <img src='main/images/chen2020topology.png' width="250" height="150"></div>
                        </td>
                        <td style="padding-bottom:15px;padding-top:15px;padding-right:5px;width:75%;vertical-align:middle">
                            <p>
                                <a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w17/Chen_Topology-Aware_Single-Image_3D_Shape_Reconstruction_CVPRW_2020_paper.pdf">
                                    <papertitle>Topology-Aware Single-Image 3D Shape Reconstruction</papertitle>
                                </a>
                                <br>
                                <strong>Qimin Chen</strong>,
                                <a href="">Vincent Nguyen</a>,
                                <a href="">Feng Han</a>,
                                <a href="">Raimondas Kiveris</a>,
                                <a href="http://pages.ucsd.edu/~ztu/">Zhuowen Tu</a>
                                <br>
                                <em>CVPR Workshop on Learning 3D Generative Models <a href="https://learn3dgen.github.io/">
                                    (CVPRW)</a>,</em> 2020
                                <br>
                                <a href="http://openaccess.thecvf.com/content_CVPRW_2020/papers/w17/Chen_Topology-Aware_Single-Image_3D_Shape_Reconstruction_CVPRW_2020_paper.pdf">pdf</a> /
                                <a href="https://drive.google.com/file/d/1YiCK5TOhV1Vv3aYJhgbLQfy-DcUJbroh/view?usp=sharing">poster</a> /
                                <a href="main/data/chen2020topology.bib">bibtex</a>
                            </p>
                            <p></p>
                            <p>
                                Composing volumetric-based generative model with topology-awareness auto-encoder allows them to learn
                                high-level topological properties such as genus and connectivity for 3D shape reconstruction.
                            </p>
                        </td>
                    </tr>

                    </tbody>
                </table>

                <!-- Working experience -->
                <table style="width:100%;border:0px;border-spacing:0px;
                border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding-bottom:10px;padding-top:10px;padding-left:20px;padding-right:10px;width:100%;vertical-align:middle">
                            <heading>Working experience</heading>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
                margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding-bottom:10px;padding-top:10px;padding-left:20px;padding-right:10px;width:100%;vertical-align:middle">
                            <p>Incoming Adobe Internship, May - TBC, 2024</p>
                            <p>Adobe Internship, May - November 2023</p>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <!-- Teaching -->
                <table style="width:100%;border:0px;border-spacing:0px;
                border-collapse:separate;margin-right:auto;margin-left:auto;margin-top:20px">
                    <tbody>
                    <tr>
                        <td style="padding-bottom:10px;padding-top:10px;padding-left:20px;padding-right:10px;width:100%;vertical-align:middle">
                            <heading>Teaching</heading>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
                margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr style="padding:0px">
                        <td style="padding-bottom:10px;padding-top:10px;padding-left:0px;padding-right:10px;width:100%;vertical-align:middle">
                            <ul>
                                <li>
                                    <span style="float:left;">TA - <strong>CMPT 762: Computer Vision</strong></span>
                                    <span style="float:right;">SFU [Spring 22]</span>
                                </li>
                                <li>
                                    <span style="float:left;">TA - <strong>CMPT 464/764: Geometric Modeling in Computer Graphics</strong></span>
                                    <span style="float:right;">SFU [Fall 21]</span>
                                </li>
                                <li>
                                    <span style="float:left;">Tutor - <strong>CSE 152: Introduction to Computer Vision</strong></span>
                                    <span style="float:right;">UCSD [Spring 19]</span>
                                </li>
                            </ul>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <!-- Reviewer -->
                <table style="width:100%;border:0px;border-spacing:0px;
                border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding-bottom:10px;padding-top:10px;padding-left:20px;padding-right:10px;width:100%;vertical-align:middle">
                            <heading>Reviewer</heading>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;
                margin-right:auto;margin-left:auto;">
                    <tbody>
                    <tr>
                        <td style="padding-bottom:10px;padding-top:10px;padding-left:20px;padding-right:10px;width:100%;vertical-align:middle">
                            <p>SIGGRAPH Asia 2023, CVPR 2023, CVPR 2024, ECCV 2024</p>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <!-- Bottom -->
                <table style="width:100%;vertical-align:center;border:0px;border-spacing:0px;padding:0px">
                    <tr>
                        <td>
                            <br>
                            <p style="text-align:right;font-size:small;margin-bottom: 0">
                                <a href="https://www.cs.sfu.ca/~haoz/">&#10025;</a>
                                <a href="https://cseweb.ucsd.edu/~kriegman/">&#10025;</a>
                                <a href="http://pages.ucsd.edu/~ztu/">&#10025;</a>
                                <a href="http://ai.stanford.edu/~ssrinath">&#10025;</a>
                                <a href="https://chenshen.xyz">&#10025;</a>
                                <a href="https://orzyt.cn">&#10025;</a>
                                <a href="http://floatingsong.com/">&#10025;</a>
                            </p>
                            <hr style="margin-bottom:0;margin-top: 0">
                            <p style="text-align:left;font-size:10px">
                                <span style="font-size:10px;float:right">
                                    Layout inspired by <a href="https://jonbarron.info/" style="font-size: 10px;">Jon Barron</a>
                                    . Thank you Jon. &copy; 2023
                                </span>
                                Deep Learning and Keep Learning.
                            </p>
                        </td>
                    </tr>
                </table>

            </td>
        </tr>
        </tbody>
    </table>
</body>
