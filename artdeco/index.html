<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <title>ART-DECO</title>
</head>

<body>
  <div class="container">
    <div style="text-align: center; margin-top: 100px;">
      <h2> ART-DECO: Arbitrary Text Guidance for 3D Detailizer Construction </h2>
      <div style="margin-top: 15px;">
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://qiminchen.github.io/">Qimin Chen<sup>1</sup></a> </span>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://yyuezhi.github.io/">Yuezhi Yang<sup>2</sup></a> </span>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://yifita.netlify.app/">Wang Yifan<sup>3</sup></a> </span>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="http://www.vovakim.com/">Vladimir G. Kim<sup>3</sup></a> </span>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://www.cse.iitb.ac.in/~sidch/">Siddhartha Chaudhuri<sup>3</sup></a> </span>
        <span style="margin-right: 15px; font-size: 1.3em;"><a href="https://www.cs.sfu.ca/~haoz/">Hao Zhang<sup>1</sup></a> </span>
        <span style="font-size: 1.3em;"><a href="https://czq142857.github.io/">Zhiqin Chen<sup>3</sup></a> </span>
      </div>
      <div style="margin-top: 15px;">
        <span style="margin-right: 20px; font-size: 1.2em;"><sup>1</sup>Simon Fraser University</span>
        <span style="margin-right: 20px; font-size: 1.2em;"><sup>2</sup>The University of Texas at Austin</span>
        <span style="margin-right: 20px; font-size: 1.2em;"><sup>3</sup>Adobe Research</span>
      </div>
    </div>

    <div style="margin-top: 15px; text-align: center;">
      <span style="margin-right: 15px; font-size: 1.3em;">
        <a href="https://arxiv.org/abs/2505.20431">
          [Paper (SIGGRAPH Asia 2025 Conference)]</a>
        <a href="https://github.com/qiminchen/ART-DECO">[Code]</a>
    </div>

    <div style="margin-top: 50px;">
      <div class="text-center">
        <img src="representative_image.jpg" width=100% class="img-fluid">
      </div>
      <div style="margin-top: 35px;">
        <p>
            Our 3D detailizer is trained using a text prompt, which defines the shape class and guides the stylization and detailization of any number of coarse 3D
            shapes with varied structures. Once trained, our detailizer can instantaneously (in <1s) transform a coarse proxy into a detailed 3D shape, whose overall
            structure respects the input proxy and the appearance and style of the generated details follow the prompt.
        </p>
      </div>
      <div style="margin-top: 35px;">
        <video width=100% controls autoplay muted>
          <source src="demo.mp4" type="video/mp4">
          Your browser does not support HTML video.
        </video>
        <div style="margin-top: 35px;">
        <p>
            Our interactive modeling interface allows users to iteratively edit a coarse voxel grid, select a text prompt, 
            and visualize the resulting detailed and textured 3D shape in a real-time manner.
        </p>
      </div>
      </div>
    </div>

    <div style="margin-top: 30px;">
      <h3 class="text-center">
        - Abstract -
      </h3>
      <p style="font-style: italic; margin-bottom: 5px;">
        We introduce a 3D detailizer, a neural model which can instantaneously (in <1s) transform a coarse 3D shape proxy 
        into a high-quality asset with detailed geometry and texture as guided by an input text prompt. Our model is trained 
        using the text prompt, which defines the shape class and characterizes the appearance and fine-grained style of the 
        generated details. The coarse 3D proxy, which can be easily varied and adjusted (e.g., via user editing), provides 
        structure control over the final shape. Importantly, our detailizer is not optimized for a single shape; it is the 
        result of distilling a generative model, so that it can be reused, without retraining, to generate any number of shapes, 
        with varied structures, whose local details all share a consistent style and appearance. Our detailizer training utilizes 
        a pretrained multi-view image diffusion model, with text conditioning, to distill the foundational knowledge therein 
        into our detailizer via Score Distillation Sampling (SDS). To improve SDS and enable our detailizer architecture to 
        learn generalizable features over complex structures, we train our model in two training stages to generate shapes 
        with increasing structural complexity. Through extensive experiments, we show that our method generates shapes of 
        superior quality and details compared to existing text-to-3D models under varied structure control. Our detailizer 
        can refine a coarse shape in less than a second, making it possible to interactively author and adjust 3D shapes. 
        Furthermore, the user-imposed structure control can lead to creative, and hence out-of-distribution, 3D asset generations 
        that are beyond the current capabilities of leading text-to-3D generative models. We demonstrate an interactive 3D modeling 
        workflow our method enables, and its strong generalizability over styles, structures, and object categories.
      </p>
    </div>

    <div style="margin-top: 50px;">
      <h3 class="text-center">
        - Method -
      </h3>
      <div class="text-center">
        <img src="method.png" width=100% class="img-fluid">
      </div>
      <div style="margin-top: 10px;">
        <p>
          Overview of the training of our detailizer. Given a coarse voxel grid and a text prompt that describes a style, two 3D convolutional networks upsample 
          the coarse voxels into high-resolution density and albedo fields, respectively. Multi-view images are then rendered from the density and albedo fields, and a
          pretrained multi-view diffusion model conditioned on the text prompt is used as a prior for Score Distillation Sampling \(\mathcal{L}_{SDS}\). 
          The regularization loss \(\mathcal{L}_{reg}\) measures the similarity between the masks rendered from the generated shape and those from the input coarse 
          voxel grid, thus enforcing the structure of the generated shape to be consistent with the input coarse voxels.
        </p>
      </div>
    </div>

    <div style="margin-top: 50px">
      <h3 class="text-center">
        - Results -
      </h3>
      <div class="text-center">
        <img src="result_1.png" width=100% class="img-fluid">
      </div>
      <div style="margin-top: 10px;">
      <p>
        Results of text-guided detailization with input coarse voxels control. We show the input coarse voxels on the left and the text prompts on the top.
      </p>
      
    </div>

    <div style="margin-top: 50px">
      <h3 class="text-center">
        - Procedural Editing -
      </h3>
      <div class="text-center">
        <img src="procedural_editing.png" width=100% class="img-fluid">
      </div>
      <div style="margin-top: 10px;">
      <p>
        Example of procedural editing. After training the model with the text prompt <i>“an office chair with wheels and thick padding”</i>, the detailization of each
        edit takes less than one second. Our method demonstrates strong robustness to minor modifications and local edits.
      </p>
      
    </div>

    <div style="margin-top: 50px; margin-bottom: 30px;">
      <h3 class="text-center">
        - Citation -
      </h3>
      <div style="margin-top: 35px;">
        <pre><code>
          @inproceedings{chen2025artdeco,
          author = {Chen, Qimin and Yang, Yuezhi and Wang, Yifan and Kim, Vladimir G. and Chaudhuri, Siddhartha and Zhang, Hao and Chen, Zhiqin},
          title = {ART-DECO: Arbitrary Text Guidance for 3D Detailizer Construction},
          year = {2025},
          booktitle = {SIGGRAPH Asia 2025 Conference Papers},
          }
        </code></pre>
      </div>
    </div>

  </div>
</body>

</html>
